{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad81079",
   "metadata": {},
   "source": [
    "# 영상 받아서 이미지 한장씩 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d77598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 1553\n",
      "width : 1920\n",
      "height : 1080\n",
      "fps : 30.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "filepath = './11.mp4'\n",
    "video = cv2.cv2.VideoCapture(filepath)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Could not Open :\",filepath)\n",
    "    exit(0)\n",
    "    \n",
    "length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"length :\", length)\n",
    "print(\"width :\", width)\n",
    "print(\"height :\", height)\n",
    "print(\"fps :\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28553a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame number : 30\n",
      "Saved frame0.jpg\n",
      "Saved frame number : 60\n",
      "Saved frame1.jpg\n",
      "Saved frame number : 90\n",
      "Saved frame2.jpg\n",
      "Saved frame number : 120\n",
      "Saved frame3.jpg\n",
      "Saved frame number : 150\n",
      "Saved frame4.jpg\n",
      "Saved frame number : 180\n",
      "Saved frame5.jpg\n",
      "Saved frame number : 210\n",
      "Saved frame6.jpg\n",
      "Saved frame number : 240\n",
      "Saved frame7.jpg\n",
      "Saved frame number : 270\n",
      "Saved frame8.jpg\n",
      "Saved frame number : 300\n",
      "Saved frame9.jpg\n",
      "Saved frame number : 330\n",
      "Saved frame10.jpg\n",
      "Saved frame number : 360\n",
      "Saved frame11.jpg\n",
      "Saved frame number : 390\n",
      "Saved frame12.jpg\n",
      "Saved frame number : 420\n",
      "Saved frame13.jpg\n",
      "Saved frame number : 450\n",
      "Saved frame14.jpg\n",
      "Saved frame number : 480\n",
      "Saved frame15.jpg\n",
      "Saved frame number : 510\n",
      "Saved frame16.jpg\n",
      "Saved frame number : 540\n",
      "Saved frame17.jpg\n",
      "Saved frame number : 570\n",
      "Saved frame18.jpg\n",
      "Saved frame number : 600\n",
      "Saved frame19.jpg\n",
      "Saved frame number : 630\n",
      "Saved frame20.jpg\n",
      "Saved frame number : 660\n",
      "Saved frame21.jpg\n",
      "Saved frame number : 690\n",
      "Saved frame22.jpg\n",
      "Saved frame number : 720\n",
      "Saved frame23.jpg\n",
      "Saved frame number : 750\n",
      "Saved frame24.jpg\n",
      "Saved frame number : 780\n",
      "Saved frame25.jpg\n",
      "Saved frame number : 810\n",
      "Saved frame26.jpg\n",
      "Saved frame number : 840\n",
      "Saved frame27.jpg\n",
      "Saved frame number : 870\n",
      "Saved frame28.jpg\n",
      "Saved frame number : 900\n",
      "Saved frame29.jpg\n",
      "Saved frame number : 930\n",
      "Saved frame30.jpg\n",
      "Saved frame number : 960\n",
      "Saved frame31.jpg\n",
      "Saved frame number : 990\n",
      "Saved frame32.jpg\n",
      "Saved frame number : 1020\n",
      "Saved frame33.jpg\n",
      "Saved frame number : 1050\n",
      "Saved frame34.jpg\n",
      "Saved frame number : 1080\n",
      "Saved frame35.jpg\n",
      "Saved frame number : 1110\n",
      "Saved frame36.jpg\n",
      "Saved frame number : 1140\n",
      "Saved frame37.jpg\n",
      "Saved frame number : 1170\n",
      "Saved frame38.jpg\n",
      "Saved frame number : 1200\n",
      "Saved frame39.jpg\n",
      "Saved frame number : 1230\n",
      "Saved frame40.jpg\n",
      "Saved frame number : 1260\n",
      "Saved frame41.jpg\n",
      "Saved frame number : 1290\n",
      "Saved frame42.jpg\n",
      "Saved frame number : 1320\n",
      "Saved frame43.jpg\n",
      "Saved frame number : 1350\n",
      "Saved frame44.jpg\n",
      "Saved frame number : 1380\n",
      "Saved frame45.jpg\n",
      "Saved frame number : 1410\n",
      "Saved frame46.jpg\n",
      "Saved frame number : 1440\n",
      "Saved frame47.jpg\n",
      "Saved frame number : 1470\n",
      "Saved frame48.jpg\n"
     ]
    }
   ],
   "source": [
    "new_path = './new_image/' # 이미지가 담길 폴더\n",
    "import cv2\n",
    "vidcap = cv2.VideoCapture(filepath)  # 영상이 있는 경로 \n",
    "count = 0 \n",
    "\n",
    "while(vidcap.isOpened()): \n",
    "    ret, image = vidcap.read() # 이미지 사이즈 960x540으로 변경 \n",
    "    if ret:\n",
    "        # image = cv2.resize(image, (960, 540)) # 30프레임당 하나씩 이미지 추출 \n",
    "        if(int(vidcap.get(1)) % 30 == 0): \n",
    "            print('Saved frame number : ' + str(int(vidcap.get(1)))) # 추출된 이미지가 저장되는 경로 \n",
    "            cv2.imwrite(new_path+\"frame%d.png\" % count, image) #\n",
    "            print('Saved frame%d.jpg' % count) \n",
    "            count += 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed35f67",
   "metadata": {},
   "source": [
    "# 연속된 이미지 불러와서 검출 -> 분류 -> 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0108331",
   "metadata": {},
   "source": [
    "- 연속된 이미지 파일명 : 20200602_1.jpg (이런식으로 파일명을 변경함) \n",
    "- 여기서 검출된 신호등 20200602_1_1, 20200602_1_2 ... 이런식으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90d4b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## green yellow red 모델들\n",
    "\n",
    "# 파일명 시작 숫자 설정\n",
    "seq = 1 # 채번 변수 통일 20220308 by yjlim\n",
    "\n",
    "# 추출 이미지 저장 위치 설정\n",
    "# 이미지 한장으로 테스트 하는 거라서 디렉토리 분류 할 필요 없이 한 폴더에 다 담기\n",
    "path = './vi_data2/'\n",
    "\n",
    "first_detect = []\n",
    "\n",
    "##### 1. green #####\n",
    "def green(img, name, X, Y, W, H):\n",
    "    global seq, path_g, path\n",
    "    \n",
    "    ## 파일 불러오기\n",
    "    B = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    name = name.split('.')\n",
    "    \n",
    "    # ROI 지정\n",
    "    roi = B[Y:Y+H, X:X+W]\n",
    "    roi2 = roi.copy()    \n",
    "\n",
    "    ## 초록색 부분 추출\n",
    "    # hsv 영역 전환\n",
    "    roi2_hsv = cv2.cvtColor(roi2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 색 범위 지정\n",
    "    low = (43, 40, 120)\n",
    "    up = (95, 255, 255)\n",
    "\n",
    "    # 범위내의 픽셀들은 흰색, 나머지 검은색\n",
    "    roi2_mask = cv2.inRange(roi2_hsv, low, up)\n",
    "    \n",
    "    # 바이너리 이미지를 마스크로 사용하여 원본이미지에서 범위값에 해당하는 영상부분을 획득\n",
    "    roi2_result = cv2.bitwise_and(roi2, roi2, mask = roi2_mask)\n",
    "    \n",
    "    ## 모폴 침식 사용\n",
    "    # 구조화 요소 커널, 사각형 (2x2) 생성\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    \n",
    "    # 열림 연산 적용 # yjlim 추가\n",
    "    erosion1 = cv2.morphologyEx(roi2_result, cv2.MORPH_OPEN, k)\n",
    "    \n",
    "    # 침식 연산 적용\n",
    "    erosion2 = cv2.erode(roi2_result, k)\n",
    "    \n",
    "    erosion3 = erosion1.copy()\n",
    "\n",
    "    ## 색 영역 변환\n",
    "    # FindContours support only 8uC1 and 32sC1 images,\n",
    "    # HSV 이미지는 contour 기능을 쓸 수 없으므로 HSV->BGR->GRAY 로 전환하자\n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_HSV2BGR)    \n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    ## contour 직사각형으로 출력\n",
    "    position = []\n",
    "    contours, hierarchy = cv2.findContours(erosion3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # cnt를 일일이 확인해서 좌표상으로 크게 차이 안나는 것들(잡음)은 추가안함(너무 작은 직사각형, 한쪽으로 길쭉한 직사각형 제외)\n",
    "        if (w >= 7) and (h >= 7) and (abs(w - h) <= 6):\n",
    "            cv2.rectangle(erosion3, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "            position.append((x, y, w, h))\n",
    "            \n",
    "    ## 추출한 신호등만 별도의 이미지로 저장\n",
    "    if position:\n",
    "        for a in position:\n",
    "            # 가로, 세로 높이 비교해서 큰 값으로 길이 설정 # yjlim\n",
    "            if a[2] >= a[3]:\n",
    "                length = a[2]\n",
    "            else:\n",
    "                length = a[3]\n",
    "                \n",
    "            interval_x = int(length / 3) # 너비 3등분\n",
    "            interval_y = int(a[3] / 4) # 높이 4등분\n",
    "            \n",
    "            if a[1] - interval_y > 0 and X + a[0] - 2 * length - 2 * interval_x > 0:\n",
    "                real3 = B[a[1] - interval_y:a[1] + a[3] + interval_y,\\\n",
    "                        X + a[0] - 2 * length - 2 * interval_x:X + a[0] + length + interval_x]\n",
    "                print(img + '///G' + str(seq) + '.jpg')\n",
    "                first_detect.append([[a[1] - interval_y, a[1] + a[3] + interval_y, X + a[0] - 2 * length - 2 * interval_x, X + a[0] + length + interval_x], name[0] + '_' + str(seq)])\n",
    "                cv2.imwrite(path + name[0] + '_' + str(seq) + '.jpg', real3)\n",
    "                seq = seq + 1\n",
    "                \n",
    "                \n",
    "                \n",
    "##### 2. yellow #####\n",
    "def yellow(img, name, X, Y, W, H):\n",
    "    global seq, path_y, path\n",
    "    \n",
    "    name = name.split('.')\n",
    "    \n",
    "    ## 파일 불러오기\n",
    "    B = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # ROI 지정\n",
    "    roi = B[Y:Y+H,X:X+W]\n",
    "    roi2 = roi.copy()\n",
    "\n",
    "    ## 노랑색 부분 추출\n",
    "    # hsv 영역 전환\n",
    "    roi2_hsv = cv2.cvtColor(roi2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 색 범위 지정\n",
    "    low = (10, 10, 110)\n",
    "    up = (31, 255, 255)\n",
    "    # low = (20, 20, 100)\n",
    "    # up = (30, 255, 255)\n",
    "\n",
    "    roi2_mask = cv2.inRange(roi2_hsv, low, up)\n",
    "    roi2_result = cv2.bitwise_and(roi2, roi2, mask = roi2_mask)\n",
    "\n",
    "    ## 모폴 침식 사용\n",
    "    # 구조화 요소 커널, 사각형 (2x2) 생성\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    \n",
    "    # 열림 연산 적용 # yjlim 추가\n",
    "    erosion1 = cv2.morphologyEx(roi2_result, cv2.MORPH_OPEN, k)\n",
    "    \n",
    "    # 침식 연산 적용\n",
    "    erosion = cv2.erode(roi2_result, k)\n",
    "    \n",
    "    erosion3 = erosion1.copy()\n",
    "\n",
    "    \n",
    "    ## 색 영역 변환\n",
    "    # FindContours support only 8uC1 and 32sC1 images,\n",
    "    # HSV 이미지는 contour 기능을 쓸 수 없으므로 HSV->BGR->GRAY 로 전환하자\n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_HSV2BGR)\n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ## contour 직사각형으로 출력\n",
    "    position = []\n",
    "    contours, hierarchy = cv2.findContours(erosion3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # cnt를 일일이 확인해서 좌표상으로 크게 차이 안나는 것들(잡음)은 추가안함(너무 작은 직사각형, 한쪽으로 길쭉한 직사각형 제외)\n",
    "        if (w >= 7) and (h >= 7) and (abs(w - h) <= 6):\n",
    "            cv2.rectangle(erosion3, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "            position.append((x, y, w, h))\n",
    "\n",
    "    ## 추출한 신호등만 별도의 이미지로 저장\n",
    "    if position:\n",
    "        for a in position:\n",
    "            # 가로, 세로 높이 비교해서 큰 값으로 길이 설정 # yjlim\n",
    "            if a[2] >= a[3]:\n",
    "                length = a[2]\n",
    "            else:\n",
    "                length = a[3]\n",
    "                \n",
    "            interval_x = int(length / 3) # 너비 3등분\n",
    "            interval_y = int(a[3] / 4) # 높이 4등분\n",
    "            \n",
    "            if a[1] - interval_y > 0 and X + a[0] - length - interval_x > 0:\n",
    "                real3 = B[a[1] - interval_y:a[1] + a[3] + interval_y,\n",
    "                        X + a[0] - length - interval_x:X + a[0] + 2 * length + interval_x]\n",
    "                \n",
    "                print(img + '///Y' + str(seq) + '.jpg')\n",
    "                first_detect.append([[a[1] - interval_y,a[1] + a[3] + interval_y,X + a[0] - length - interval_x, X + a[0] + 2 * length + interval_x], name[0] + '_' + str(seq)])\n",
    "                cv2.imwrite(path + name[0] + '_' + str(seq) + '.jpg', real3)\n",
    "                seq = seq + 1\n",
    "                \n",
    "                \n",
    "                \n",
    "##### 3. red #####\n",
    "def red(img, name, X, Y, W, H):\n",
    "    global seq, path_r,path\n",
    "    \n",
    "    name = name.split('.')\n",
    "    \n",
    "    ## 파일 불러오기\n",
    "    B = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # ROI 지정\n",
    "    roi = B[Y:Y+H,X:X+W]\n",
    "    roi2 = roi.copy()\n",
    "\n",
    "    ## 빨강색 부분 추출\n",
    "    # hsv 영역 전환\n",
    "    roi2_hsv = cv2.cvtColor(roi2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 색 범위 지정\n",
    "    low = (0, 30,50)\n",
    "    up = (10, 255, 255)\n",
    "\n",
    "    roi2_mask = cv2.inRange(roi2_hsv, low, up)\n",
    "    roi2_result = cv2.bitwise_and(roi2, roi2, mask = roi2_mask)\n",
    "    \n",
    "    # 색 영역 두번째 추가\n",
    "    low3 = (150, 40, 50)\n",
    "    up3 = (180, 255, 255)\n",
    "    \n",
    "    roi3_mask = cv2.inRange(roi2_hsv, low3, up3)\n",
    "    roi3_result = cv2.bitwise_and(roi2, roi2, mask = roi3_mask)\n",
    "    \n",
    "    # 색 영역 1 + 색 영역 2  \n",
    "    result_red = roi2_result + roi3_result\n",
    "\n",
    "    ## 모폴 침식 사용\n",
    "    # 구조화 요소 커널, 사각형 (2x2) 생성\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    \n",
    "    # 열림 연산 적용 # yjlim 추가\n",
    "    erosion1 = cv2.morphologyEx(result_red, cv2.MORPH_OPEN, k)\n",
    "    \n",
    "    # 침식 연산 적용\n",
    "    erosion = cv2.erode(result_red, k)\n",
    "    \n",
    "    erosion3 = erosion1.copy()\n",
    "\n",
    "    ## 색 영역 변환\n",
    "    # FindContours support only 8uC1 and 32sC1 images,\n",
    "    # HSV 이미지는 contour 기능을 쓸 수 없으므로 HSV->BGR->GRAY 로 전환하자\n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_HSV2BGR)\n",
    "    erosion3 = cv2.cvtColor(erosion3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ## contour 직사각형으로 출력\n",
    "    position = []\n",
    "    contours, hierarchy = cv2.findContours(erosion3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # cnt를 일일이 확인해서 좌표상으로 크게 차이 안나는 것들(잡음)은 추가안함(너무 작은 직사각형, 한쪽으로 길쭉한 직사각형 제외)\n",
    "        if (w >= 7) and (h >= 7) and (abs(w - h) <= 6):\n",
    "            cv2.rectangle(erosion3, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "            position.append((x, y, w, h))\n",
    "\n",
    "    ## 추출한 신호등만 별도의 이미지로 저장\n",
    "    if position:\n",
    "        for a in position:\n",
    "            # 가로, 세로 높이 비교해서 큰 값으로 길이 설정 # yjlim\n",
    "            if a[2] >= a[3]:\n",
    "                length = a[2]\n",
    "            else:\n",
    "                length = a[3]\n",
    "                \n",
    "            interval_x = int(length / 3)\n",
    "            interval_y = int(a[3] / 4)\n",
    "            \n",
    "            if a[1] - interval_y > 0 and X + a[0] - interval_x > 0:\n",
    "                real3 = B[a[1] - interval_y:a[1] + a[3] + interval_y,\n",
    "                        X + a[0] - interval_x:X + a[0] + 3 * length + interval_x]\n",
    "                print(img + '///R' + str(seq) + '.jpg')\n",
    "                first_detect.append([[a[1] - interval_y,a[1] + a[3] + interval_y, X + a[0] - interval_x, X + a[0] + 3 * length + interval_x], name[0] + '_' + str(seq)])\n",
    "                cv2.imwrite(path + name[0] +'_'+ str(seq) + '.jpg', real3)\n",
    "                seq = seq + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de8ccf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\new_image\\frame0.png///G1.jpg\n",
      ".\\new_image\\frame0.png///G2.jpg\n",
      ".\\new_image\\frame0.png///Y3.jpg\n",
      ".\\new_image\\frame0.png///Y4.jpg\n",
      ".\\new_image\\frame0.png///Y5.jpg\n",
      ".\\new_image\\frame0.png///Y6.jpg\n",
      ".\\new_image\\frame0.png///Y7.jpg\n",
      ".\\new_image\\frame0.png///R8.jpg\n",
      ".\\new_image\\frame1.png///G9.jpg\n",
      ".\\new_image\\frame1.png///G10.jpg\n",
      ".\\new_image\\frame1.png///Y11.jpg\n",
      ".\\new_image\\frame1.png///R12.jpg\n",
      ".\\new_image\\frame10.png///G13.jpg\n",
      ".\\new_image\\frame10.png///G14.jpg\n",
      ".\\new_image\\frame11.png///G15.jpg\n",
      ".\\new_image\\frame11.png///G16.jpg\n",
      ".\\new_image\\frame13.png///Y17.jpg\n",
      ".\\new_image\\frame18.png///Y18.jpg\n",
      ".\\new_image\\frame19.png///Y19.jpg\n",
      ".\\new_image\\frame20.png///G20.jpg\n",
      ".\\new_image\\frame20.png///G21.jpg\n",
      ".\\new_image\\frame20.png///G22.jpg\n",
      ".\\new_image\\frame20.png///Y23.jpg\n",
      ".\\new_image\\frame20.png///R24.jpg\n",
      ".\\new_image\\frame21.png///R25.jpg\n",
      ".\\new_image\\frame21.png///R26.jpg\n",
      ".\\new_image\\frame21.png///R27.jpg\n",
      ".\\new_image\\frame21.png///R28.jpg\n",
      ".\\new_image\\frame22.png///Y29.jpg\n",
      ".\\new_image\\frame22.png///R30.jpg\n",
      ".\\new_image\\frame22.png///R31.jpg\n",
      ".\\new_image\\frame22.png///R32.jpg\n",
      ".\\new_image\\frame23.png///Y33.jpg\n",
      ".\\new_image\\frame23.png///R34.jpg\n",
      ".\\new_image\\frame24.png///Y35.jpg\n",
      ".\\new_image\\frame24.png///Y36.jpg\n",
      ".\\new_image\\frame24.png///Y37.jpg\n",
      ".\\new_image\\frame24.png///R38.jpg\n",
      ".\\new_image\\frame25.png///Y39.jpg\n",
      ".\\new_image\\frame25.png///R40.jpg\n",
      ".\\new_image\\frame25.png///R41.jpg\n",
      ".\\new_image\\frame25.png///R42.jpg\n",
      ".\\new_image\\frame25.png///R43.jpg\n",
      ".\\new_image\\frame26.png///Y44.jpg\n",
      ".\\new_image\\frame26.png///Y45.jpg\n",
      ".\\new_image\\frame26.png///Y46.jpg\n",
      ".\\new_image\\frame26.png///Y47.jpg\n",
      ".\\new_image\\frame26.png///R48.jpg\n",
      ".\\new_image\\frame26.png///R49.jpg\n",
      ".\\new_image\\frame26.png///R50.jpg\n",
      ".\\new_image\\frame26.png///R51.jpg\n",
      ".\\new_image\\frame27.png///Y52.jpg\n",
      ".\\new_image\\frame27.png///Y53.jpg\n",
      ".\\new_image\\frame27.png///Y54.jpg\n",
      ".\\new_image\\frame27.png///Y55.jpg\n",
      ".\\new_image\\frame27.png///R56.jpg\n",
      ".\\new_image\\frame27.png///R57.jpg\n",
      ".\\new_image\\frame27.png///R58.jpg\n",
      ".\\new_image\\frame28.png///Y59.jpg\n",
      ".\\new_image\\frame28.png///Y60.jpg\n",
      ".\\new_image\\frame28.png///Y61.jpg\n",
      ".\\new_image\\frame28.png///R62.jpg\n",
      ".\\new_image\\frame28.png///R63.jpg\n",
      ".\\new_image\\frame28.png///R64.jpg\n",
      ".\\new_image\\frame28.png///R65.jpg\n",
      ".\\new_image\\frame28.png///R66.jpg\n",
      ".\\new_image\\frame29.png///Y67.jpg\n",
      ".\\new_image\\frame29.png///Y68.jpg\n",
      ".\\new_image\\frame29.png///Y69.jpg\n",
      ".\\new_image\\frame29.png///Y70.jpg\n",
      ".\\new_image\\frame29.png///Y71.jpg\n",
      ".\\new_image\\frame29.png///Y72.jpg\n",
      ".\\new_image\\frame29.png///R73.jpg\n",
      ".\\new_image\\frame29.png///R74.jpg\n",
      ".\\new_image\\frame29.png///R75.jpg\n",
      ".\\new_image\\frame30.png///Y76.jpg\n",
      ".\\new_image\\frame30.png///Y77.jpg\n",
      ".\\new_image\\frame30.png///R78.jpg\n",
      ".\\new_image\\frame30.png///R79.jpg\n",
      ".\\new_image\\frame30.png///R80.jpg\n",
      ".\\new_image\\frame30.png///R81.jpg\n",
      ".\\new_image\\frame30.png///R82.jpg\n",
      ".\\new_image\\frame30.png///R83.jpg\n",
      ".\\new_image\\frame31.png///Y84.jpg\n",
      ".\\new_image\\frame31.png///Y85.jpg\n",
      ".\\new_image\\frame31.png///R86.jpg\n",
      ".\\new_image\\frame31.png///R87.jpg\n",
      ".\\new_image\\frame31.png///R88.jpg\n",
      ".\\new_image\\frame31.png///R89.jpg\n",
      ".\\new_image\\frame31.png///R90.jpg\n",
      ".\\new_image\\frame32.png///Y91.jpg\n",
      ".\\new_image\\frame32.png///Y92.jpg\n",
      ".\\new_image\\frame32.png///R93.jpg\n",
      ".\\new_image\\frame32.png///R94.jpg\n",
      ".\\new_image\\frame32.png///R95.jpg\n",
      ".\\new_image\\frame33.png///Y96.jpg\n",
      ".\\new_image\\frame33.png///Y97.jpg\n",
      ".\\new_image\\frame33.png///Y98.jpg\n",
      ".\\new_image\\frame33.png///R99.jpg\n",
      ".\\new_image\\frame33.png///R100.jpg\n",
      ".\\new_image\\frame33.png///R101.jpg\n",
      ".\\new_image\\frame34.png///Y102.jpg\n",
      ".\\new_image\\frame34.png///R103.jpg\n",
      ".\\new_image\\frame34.png///R104.jpg\n",
      ".\\new_image\\frame34.png///R105.jpg\n",
      ".\\new_image\\frame34.png///R106.jpg\n",
      ".\\new_image\\frame35.png///Y107.jpg\n",
      ".\\new_image\\frame35.png///Y108.jpg\n",
      ".\\new_image\\frame35.png///R109.jpg\n",
      ".\\new_image\\frame35.png///R110.jpg\n",
      ".\\new_image\\frame35.png///R111.jpg\n",
      ".\\new_image\\frame35.png///R112.jpg\n",
      ".\\new_image\\frame36.png///Y113.jpg\n",
      ".\\new_image\\frame36.png///Y114.jpg\n",
      ".\\new_image\\frame36.png///Y115.jpg\n",
      ".\\new_image\\frame36.png///Y116.jpg\n",
      ".\\new_image\\frame36.png///Y117.jpg\n",
      ".\\new_image\\frame36.png///R118.jpg\n",
      ".\\new_image\\frame36.png///R119.jpg\n",
      ".\\new_image\\frame36.png///R120.jpg\n",
      ".\\new_image\\frame36.png///R121.jpg\n",
      ".\\new_image\\frame36.png///R122.jpg\n",
      ".\\new_image\\frame37.png///Y123.jpg\n",
      ".\\new_image\\frame37.png///Y124.jpg\n",
      ".\\new_image\\frame37.png///Y125.jpg\n",
      ".\\new_image\\frame37.png///R126.jpg\n",
      ".\\new_image\\frame37.png///R127.jpg\n",
      ".\\new_image\\frame37.png///R128.jpg\n",
      ".\\new_image\\frame38.png///Y129.jpg\n",
      ".\\new_image\\frame38.png///Y130.jpg\n",
      ".\\new_image\\frame38.png///R131.jpg\n",
      ".\\new_image\\frame38.png///R132.jpg\n",
      ".\\new_image\\frame38.png///R133.jpg\n",
      ".\\new_image\\frame39.png///R134.jpg\n",
      ".\\new_image\\frame39.png///R135.jpg\n",
      ".\\new_image\\frame39.png///R136.jpg\n",
      ".\\new_image\\frame4.png///Y137.jpg\n",
      ".\\new_image\\frame4.png///R138.jpg\n",
      ".\\new_image\\frame40.png///Y139.jpg\n",
      ".\\new_image\\frame40.png///Y140.jpg\n",
      ".\\new_image\\frame40.png///R141.jpg\n",
      ".\\new_image\\frame40.png///R142.jpg\n",
      ".\\new_image\\frame40.png///R143.jpg\n",
      ".\\new_image\\frame40.png///R144.jpg\n",
      ".\\new_image\\frame41.png///Y145.jpg\n",
      ".\\new_image\\frame41.png///Y146.jpg\n",
      ".\\new_image\\frame41.png///R147.jpg\n",
      ".\\new_image\\frame41.png///R148.jpg\n",
      ".\\new_image\\frame41.png///R149.jpg\n",
      ".\\new_image\\frame41.png///R150.jpg\n",
      ".\\new_image\\frame42.png///Y151.jpg\n",
      ".\\new_image\\frame42.png///Y152.jpg\n",
      ".\\new_image\\frame42.png///Y153.jpg\n",
      ".\\new_image\\frame42.png///R154.jpg\n",
      ".\\new_image\\frame42.png///R155.jpg\n",
      ".\\new_image\\frame42.png///R156.jpg\n",
      ".\\new_image\\frame43.png///Y157.jpg\n",
      ".\\new_image\\frame43.png///Y158.jpg\n",
      ".\\new_image\\frame43.png///R159.jpg\n",
      ".\\new_image\\frame43.png///R160.jpg\n",
      ".\\new_image\\frame43.png///R161.jpg\n",
      ".\\new_image\\frame43.png///R162.jpg\n",
      ".\\new_image\\frame43.png///R163.jpg\n",
      ".\\new_image\\frame44.png///Y164.jpg\n",
      ".\\new_image\\frame44.png///Y165.jpg\n",
      ".\\new_image\\frame44.png///R166.jpg\n",
      ".\\new_image\\frame44.png///R167.jpg\n",
      ".\\new_image\\frame44.png///R168.jpg\n",
      ".\\new_image\\frame44.png///R169.jpg\n",
      ".\\new_image\\frame44.png///R170.jpg\n",
      ".\\new_image\\frame45.png///Y171.jpg\n",
      ".\\new_image\\frame45.png///Y172.jpg\n",
      ".\\new_image\\frame45.png///R173.jpg\n",
      ".\\new_image\\frame45.png///R174.jpg\n",
      ".\\new_image\\frame45.png///R175.jpg\n",
      ".\\new_image\\frame45.png///R176.jpg\n",
      ".\\new_image\\frame46.png///Y177.jpg\n",
      ".\\new_image\\frame46.png///Y178.jpg\n",
      ".\\new_image\\frame46.png///Y179.jpg\n",
      ".\\new_image\\frame46.png///Y180.jpg\n",
      ".\\new_image\\frame46.png///R181.jpg\n",
      ".\\new_image\\frame46.png///R182.jpg\n",
      ".\\new_image\\frame46.png///R183.jpg\n",
      ".\\new_image\\frame46.png///R184.jpg\n",
      ".\\new_image\\frame47.png///Y185.jpg\n",
      ".\\new_image\\frame47.png///Y186.jpg\n",
      ".\\new_image\\frame47.png///Y187.jpg\n",
      ".\\new_image\\frame47.png///Y188.jpg\n",
      ".\\new_image\\frame47.png///Y189.jpg\n",
      ".\\new_image\\frame47.png///R190.jpg\n",
      ".\\new_image\\frame47.png///R191.jpg\n",
      ".\\new_image\\frame47.png///R192.jpg\n",
      ".\\new_image\\frame47.png///R193.jpg\n",
      ".\\new_image\\frame48.png///Y194.jpg\n",
      ".\\new_image\\frame48.png///Y195.jpg\n",
      ".\\new_image\\frame48.png///Y196.jpg\n",
      ".\\new_image\\frame48.png///R197.jpg\n",
      ".\\new_image\\frame48.png///R198.jpg\n",
      ".\\new_image\\frame48.png///R199.jpg\n",
      ".\\new_image\\frame48.png///R200.jpg\n",
      ".\\new_image\\frame48.png///R201.jpg\n",
      ".\\new_image\\frame48.png///R202.jpg\n",
      ".\\new_image\\frame48.png///R203.jpg\n",
      ".\\new_image\\frame5.png///R204.jpg\n",
      ".\\new_image\\frame5.png///R205.jpg\n",
      ".\\new_image\\frame5.png///R206.jpg\n",
      ".\\new_image\\frame5.png///R207.jpg\n",
      ".\\new_image\\frame5.png///R208.jpg\n",
      ".\\new_image\\frame5.png///R209.jpg\n",
      ".\\new_image\\frame7.png///R210.jpg\n",
      ".\\new_image\\frame8.png///R211.jpg\n",
      ".\\new_image\\frame9.png///G212.jpg\n",
      ".\\new_image\\frame9.png///G213.jpg\n",
      ".\\new_image\\frame9.png///R214.jpg\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# images에 있는 모든 jpg 파일을 img_files 리스트에 추가\n",
    "# 연속된 이미지가 담긴 폴더\n",
    "#img_files = glob.glob('./video/*.jpg')\n",
    "img_files = glob.glob('.\\\\new_image\\\\*.png')\n",
    "img_files.sort() # 순서대로 정렬\n",
    "\n",
    "# 이미지 없을때 예외처리\n",
    "if not img_files:\n",
    "    print(\"jpg 이미지가 없다..\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# 슬라이드 쇼 반복을 위한 반복문\n",
    "count = len(img_files)\n",
    "index = 0\n",
    "\n",
    "while index < count:\n",
    "    img = cv2.imread(img_files[index])\n",
    "    name = img_files[index].split('\\\\')[2]\n",
    "    filepath = img_files[index]\n",
    "    \n",
    "\t# 예외처리\n",
    "    if img is None:     \n",
    "        print(\"이미지를 불러오는데 실패했습니다.\")\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(1000) == 27:     \n",
    "        break\n",
    "\n",
    "    index += 1      \n",
    "    \n",
    "    # ROI 지정, x,y,w,h ,N 설정 완료\n",
    "    x1 = 300\n",
    "    y1 = 0\n",
    "    w1 = 1400\n",
    "    h1 = 640\n",
    "    \n",
    "    green(filepath, name, X = x1, Y = y1, W = w1, H = h1)\n",
    "    yellow(filepath, name, X = x1, Y = y1, W = w1, H = h1)\n",
    "    red(filepath, name, X = x1, Y = y1, W = w1, H = h1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c57c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2662ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e951f8d",
   "metadata": {},
   "source": [
    "### 신호등 인식 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24fd9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detection = tf.keras.models.load_model('traffic_light_detection_v16.h5') #v7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3555ed",
   "metadata": {},
   "source": [
    "#### 이미지 resize 해서 해당 폴더에 다시 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "550c692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_detection = 'vi_data2/' # 색 영역으로 검출한 모든 신호등 후보 영역 이미지\n",
    "\n",
    "file_list_d = os.listdir(path_detection)\n",
    "\n",
    "if \".DS_Store\" in file_list_d:\n",
    "    file_list_d.remove(\".DS_Store\")\n",
    "\n",
    "data_detection = []\n",
    "\n",
    "for A in file_list_d:\n",
    "    if A == \".DS_Store\":\n",
    "        continue\n",
    "        \n",
    "    img_d = cv2.imread(path_detection + A)\n",
    "    res_d = cv2.resize(img_d, dsize = (45, 15), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(path_detection + A, res_d)\n",
    "    \n",
    "for A in file_list_d:\n",
    "    if A == \".DS_Store\":\n",
    "        continue\n",
    "        \n",
    "    img3 = Image.open(path_detection + A)\n",
    "    data_detection.append(np.array(img3))\n",
    "    img3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "089f01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_detection = np.asarray(data_detection) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79df3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_detection.predict(data_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1724c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "light_order = {0 : \"negative\", 1 : \"positive\"}\n",
    "\n",
    "light_detect_img = [] # 파일명, 예측 결과(negative, positive)\n",
    "data_detection2 = [] # 신호등 이미지\n",
    "\n",
    "for i, x in enumerate(prediction):\n",
    "    pred_detect = \"\"\n",
    "    \n",
    "    if x >= 0.85:\n",
    "        pred_detect = light_order[1]\n",
    "        # print(str(i) + \"번째 신호등: \" + file_list[i] + \" : \" + light_order[1])\n",
    "    else:\n",
    "        pred_detect = light_order[0]\n",
    "        # print(str(i) + \"번째 신호등: \" + file_list[i] + \" : \" + light_order[0])\n",
    "    \n",
    "    # 신호등으로 90퍼센트 이상 인식된 이미지만 추출\n",
    "    if pred_detect == \"positive\":\n",
    "        # print(str(i) + \"번째 신호등: \" + file_list_d[i] + \" ==> \" + light_order[np.argmax(x)] + \" ::: \" + str(x[1]))\n",
    "        light_detect_img.append([file_list_d[i], light_order[np.argmax(x)]])\n",
    "\n",
    "        imgPath = path_detection + file_list_d[i]\n",
    "\n",
    "        img_detection = Image.open(imgPath)\n",
    "        data_detection2.append(np.array(img_detection)) # 신호등으로 인식된 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b4e37412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_detection2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a5f6591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['frame0_1.jpg', 'negative'],\n",
       " ['frame0_2.jpg', 'negative'],\n",
       " ['frame10_13.jpg', 'negative'],\n",
       " ['frame10_14.jpg', 'negative'],\n",
       " ['frame11_15.jpg', 'negative'],\n",
       " ['frame11_16.jpg', 'negative'],\n",
       " ['frame1_10.jpg', 'negative'],\n",
       " ['frame1_9.jpg', 'negative'],\n",
       " ['frame21_26.jpg', 'negative'],\n",
       " ['frame22_32.jpg', 'negative'],\n",
       " ['frame23_34.jpg', 'negative'],\n",
       " ['frame24_38.jpg', 'negative'],\n",
       " ['frame25_40.jpg', 'negative'],\n",
       " ['frame25_43.jpg', 'negative'],\n",
       " ['frame26_49.jpg', 'negative'],\n",
       " ['frame26_51.jpg', 'negative'],\n",
       " ['frame27_56.jpg', 'negative'],\n",
       " ['frame27_58.jpg', 'negative'],\n",
       " ['frame28_63.jpg', 'negative'],\n",
       " ['frame28_66.jpg', 'negative'],\n",
       " ['frame29_73.jpg', 'negative'],\n",
       " ['frame29_75.jpg', 'negative'],\n",
       " ['frame30_79.jpg', 'negative'],\n",
       " ['frame30_83.jpg', 'negative'],\n",
       " ['frame31_86.jpg', 'negative'],\n",
       " ['frame31_90.jpg', 'negative'],\n",
       " ['frame32_93.jpg', 'negative'],\n",
       " ['frame32_95.jpg', 'negative'],\n",
       " ['frame33_101.jpg', 'negative'],\n",
       " ['frame33_99.jpg', 'negative'],\n",
       " ['frame34_104.jpg', 'negative'],\n",
       " ['frame34_106.jpg', 'negative'],\n",
       " ['frame35_109.jpg', 'negative'],\n",
       " ['frame35_112.jpg', 'negative'],\n",
       " ['frame36_119.jpg', 'negative'],\n",
       " ['frame36_122.jpg', 'negative'],\n",
       " ['frame37_126.jpg', 'negative'],\n",
       " ['frame37_128.jpg', 'negative'],\n",
       " ['frame38_131.jpg', 'negative'],\n",
       " ['frame38_133.jpg', 'negative'],\n",
       " ['frame39_135.jpg', 'negative'],\n",
       " ['frame39_136.jpg', 'negative'],\n",
       " ['frame40_142.jpg', 'negative'],\n",
       " ['frame40_144.jpg', 'negative'],\n",
       " ['frame41_147.jpg', 'negative'],\n",
       " ['frame41_150.jpg', 'negative'],\n",
       " ['frame42_154.jpg', 'negative'],\n",
       " ['frame42_156.jpg', 'negative'],\n",
       " ['frame43_161.jpg', 'negative'],\n",
       " ['frame43_163.jpg', 'negative'],\n",
       " ['frame44_168.jpg', 'negative'],\n",
       " ['frame44_170.jpg', 'negative'],\n",
       " ['frame45_174.jpg', 'negative'],\n",
       " ['frame45_176.jpg', 'negative'],\n",
       " ['frame46_182.jpg', 'negative'],\n",
       " ['frame46_184.jpg', 'negative'],\n",
       " ['frame47_193.jpg', 'negative'],\n",
       " ['frame48_203.jpg', 'negative'],\n",
       " ['frame9_212.jpg', 'negative'],\n",
       " ['frame9_213.jpg', 'negative']]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_detect_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da74434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea6d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89d865a4",
   "metadata": {},
   "source": [
    "### 신호등 색 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ea69ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('traffic_light_0315_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d191ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 검출된 신호등 이미지를 입력 값으로 만들기\n",
    "# Path2 = 'vi_data2/'\n",
    "# file_list = os.listdir(Path2)\n",
    "# file_list.sort()\n",
    "# if \".DS_Store\" in file_list:\n",
    "#     file_list.remove(\".DS_Store\")\n",
    "\n",
    "# data2 = []\n",
    "\n",
    "# for A in file_list:\n",
    "#     if A == \".DS_Store\":\n",
    "#         continue\n",
    "#     try:\n",
    "#         img2 = cv2.imread(Path2+A)\n",
    "#         res2 = cv2.resize(img2, dsize = (45, 15), interpolation = cv2.INTER_CUBIC)\n",
    "#         cv2.imwrite(Path2+A,res2)\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "    \n",
    "# for A in file_list:\n",
    "#     if A == \".DS_Store\":\n",
    "#         continue\n",
    "#     try:\n",
    "#         img3 = Image.open(Path2 + A)\n",
    "#         data2.append(np.array(img3))\n",
    "#         img3.close()\n",
    "#     except Exception as e:\n",
    "#         print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d363f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec11bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = np.asarray(data2) / 255.0\n",
    "data_detection2 = np.asarray(data_detection2) / 255.0\n",
    "prediction = model.predict(data_detection2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66d3a7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99957085e-01, 2.33316459e-05, 1.95803077e-05],\n",
       "       [9.99926925e-01, 4.01254983e-05, 3.29030954e-05],\n",
       "       [9.99979496e-01, 1.15309012e-05, 8.90431602e-06],\n",
       "       [9.99980450e-01, 1.10346828e-05, 8.46268267e-06],\n",
       "       [9.99957681e-01, 2.39376768e-05, 1.83640877e-05],\n",
       "       [9.99940038e-01, 3.45118788e-05, 2.53377893e-05],\n",
       "       [9.96749282e-01, 1.79784559e-03, 1.45289244e-03],\n",
       "       [9.97821927e-01, 1.21571112e-03, 9.62404418e-04],\n",
       "       [9.73652641e-04, 9.98890460e-01, 1.35807510e-04],\n",
       "       [1.64743362e-03, 9.98134732e-01, 2.17770154e-04],\n",
       "       [1.21263647e-03, 9.98730242e-01, 5.71218952e-05],\n",
       "       [1.77117618e-05, 9.99980569e-01, 1.69583745e-06],\n",
       "       [1.04031712e-03, 9.98884976e-01, 7.46933292e-05],\n",
       "       [4.34146523e-06, 9.99995232e-01, 4.90463492e-07],\n",
       "       [1.42494112e-03, 9.98206139e-01, 3.68931593e-04],\n",
       "       [1.16918034e-06, 9.99998689e-01, 1.14208255e-07],\n",
       "       [3.20342579e-03, 9.96085286e-01, 7.11274566e-04],\n",
       "       [4.81337963e-07, 9.99999523e-01, 4.41134524e-08],\n",
       "       [4.80992347e-03, 9.94977415e-01, 2.12726489e-04],\n",
       "       [4.00891281e-07, 9.99999642e-01, 3.60896095e-08],\n",
       "       [7.44514633e-03, 9.91931021e-01, 6.23932283e-04],\n",
       "       [7.35556455e-07, 9.99999166e-01, 7.19610753e-08],\n",
       "       [5.57558844e-03, 9.93797839e-01, 6.26559544e-04],\n",
       "       [7.72535941e-07, 9.99999166e-01, 7.61202159e-08],\n",
       "       [2.53527868e-03, 9.97377038e-01, 8.76900231e-05],\n",
       "       [6.10800157e-07, 9.99999404e-01, 5.79652450e-08],\n",
       "       [5.84539818e-03, 9.93785024e-01, 3.69620800e-04],\n",
       "       [5.99153566e-07, 9.99999404e-01, 5.62277265e-08],\n",
       "       [9.05251056e-07, 9.99998927e-01, 9.29896231e-08],\n",
       "       [1.90698728e-03, 9.97989535e-01, 1.03492814e-04],\n",
       "       [6.26650522e-04, 9.99318361e-01, 5.49943579e-05],\n",
       "       [5.59341345e-07, 9.99999404e-01, 5.36008073e-08],\n",
       "       [3.42842797e-03, 9.96406853e-01, 1.64734665e-04],\n",
       "       [1.18161586e-06, 9.99998689e-01, 1.27749928e-07],\n",
       "       [5.87524730e-04, 9.99379992e-01, 3.23587774e-05],\n",
       "       [1.11300210e-06, 9.99998808e-01, 1.20754819e-07],\n",
       "       [2.35248148e-03, 9.97552693e-01, 9.48592642e-05],\n",
       "       [8.20386106e-07, 9.99999046e-01, 8.20298922e-08],\n",
       "       [2.66517675e-03, 9.97253478e-01, 8.12581056e-05],\n",
       "       [9.59678459e-07, 9.99998927e-01, 9.75188570e-08],\n",
       "       [9.33252391e-04, 9.99019027e-01, 4.77886679e-05],\n",
       "       [8.35628327e-07, 9.99999046e-01, 8.23811135e-08],\n",
       "       [1.30136148e-03, 9.98626351e-01, 7.22203404e-05],\n",
       "       [7.60977514e-07, 9.99999166e-01, 7.40364925e-08],\n",
       "       [7.86901859e-04, 9.99141574e-01, 7.14965281e-05],\n",
       "       [8.35972628e-07, 9.99999046e-01, 8.33483824e-08],\n",
       "       [4.46768187e-04, 9.99514937e-01, 3.82128310e-05],\n",
       "       [6.68234406e-07, 9.99999166e-01, 6.50218226e-08],\n",
       "       [8.41379981e-04, 9.99098301e-01, 6.03312146e-05],\n",
       "       [6.11940550e-07, 9.99999404e-01, 5.79225841e-08],\n",
       "       [2.69369641e-03, 9.97075200e-01, 2.31071361e-04],\n",
       "       [1.91170511e-06, 9.99997854e-01, 2.20928584e-07],\n",
       "       [2.45651919e-02, 9.74512696e-01, 9.22170118e-04],\n",
       "       [7.73641295e-06, 9.99991179e-01, 1.12029682e-06],\n",
       "       [1.78232475e-03, 9.97692943e-01, 5.24758594e-04],\n",
       "       [1.27790245e-05, 9.99985218e-01, 1.99742249e-06],\n",
       "       [1.11776470e-04, 9.99863625e-01, 2.45883366e-05],\n",
       "       [3.14961304e-04, 9.99602377e-01, 8.26667674e-05],\n",
       "       [9.99947190e-01, 2.87887542e-05, 2.39521542e-05],\n",
       "       [9.99965549e-01, 1.89254151e-05, 1.54658865e-05]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de875418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_detect) # 처음 색영역으로 신호등 후보 영역 검출한 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02f10cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 신호등: frame0_1.jpg : green\n",
      "1번째 신호등: frame0_2.jpg : green\n",
      "2번째 신호등: frame10_13.jpg : green\n",
      "3번째 신호등: frame10_14.jpg : green\n",
      "4번째 신호등: frame11_15.jpg : green\n",
      "5번째 신호등: frame11_16.jpg : green\n",
      "6번째 신호등: frame1_10.jpg : green\n",
      "7번째 신호등: frame1_9.jpg : green\n",
      "8번째 신호등: frame21_26.jpg : red\n",
      "9번째 신호등: frame22_32.jpg : red\n",
      "10번째 신호등: frame23_34.jpg : red\n",
      "11번째 신호등: frame24_38.jpg : red\n",
      "12번째 신호등: frame25_40.jpg : red\n",
      "13번째 신호등: frame25_43.jpg : red\n",
      "14번째 신호등: frame26_49.jpg : red\n",
      "15번째 신호등: frame26_51.jpg : red\n",
      "16번째 신호등: frame27_56.jpg : red\n",
      "17번째 신호등: frame27_58.jpg : red\n",
      "18번째 신호등: frame28_63.jpg : red\n",
      "19번째 신호등: frame28_66.jpg : red\n",
      "20번째 신호등: frame29_73.jpg : red\n",
      "21번째 신호등: frame29_75.jpg : red\n",
      "22번째 신호등: frame30_79.jpg : red\n",
      "23번째 신호등: frame30_83.jpg : red\n",
      "24번째 신호등: frame31_86.jpg : red\n",
      "25번째 신호등: frame31_90.jpg : red\n",
      "26번째 신호등: frame32_93.jpg : red\n",
      "27번째 신호등: frame32_95.jpg : red\n",
      "28번째 신호등: frame33_101.jpg : red\n",
      "29번째 신호등: frame33_99.jpg : red\n",
      "30번째 신호등: frame34_104.jpg : red\n",
      "31번째 신호등: frame34_106.jpg : red\n",
      "32번째 신호등: frame35_109.jpg : red\n",
      "33번째 신호등: frame35_112.jpg : red\n",
      "34번째 신호등: frame36_119.jpg : red\n",
      "35번째 신호등: frame36_122.jpg : red\n",
      "36번째 신호등: frame37_126.jpg : red\n",
      "37번째 신호등: frame37_128.jpg : red\n",
      "38번째 신호등: frame38_131.jpg : red\n",
      "39번째 신호등: frame38_133.jpg : red\n",
      "40번째 신호등: frame39_135.jpg : red\n",
      "41번째 신호등: frame39_136.jpg : red\n",
      "42번째 신호등: frame40_142.jpg : red\n",
      "43번째 신호등: frame40_144.jpg : red\n",
      "44번째 신호등: frame41_147.jpg : red\n",
      "45번째 신호등: frame41_150.jpg : red\n",
      "46번째 신호등: frame42_154.jpg : red\n",
      "47번째 신호등: frame42_156.jpg : red\n",
      "48번째 신호등: frame43_161.jpg : red\n",
      "49번째 신호등: frame43_163.jpg : red\n",
      "50번째 신호등: frame44_168.jpg : red\n",
      "51번째 신호등: frame44_170.jpg : red\n",
      "52번째 신호등: frame45_174.jpg : red\n",
      "53번째 신호등: frame45_176.jpg : red\n",
      "54번째 신호등: frame46_182.jpg : red\n",
      "55번째 신호등: frame46_184.jpg : red\n",
      "56번째 신호등: frame47_193.jpg : red\n",
      "57번째 신호등: frame48_203.jpg : red\n",
      "58번째 신호등: frame9_212.jpg : green\n",
      "59번째 신호등: frame9_213.jpg : green\n"
     ]
    }
   ],
   "source": [
    "light_order = {0 : \"green\", 1 : \"red\", 2 : \"yellow\", 3 : \"unknown\"}\n",
    "\n",
    "# 신호등 파일명과 색을 한 리스트에 담기 \n",
    "detect_img = [] \n",
    "\n",
    "for i, x in enumerate(prediction):\n",
    "    count = 0\n",
    "    for y in x:\n",
    "        if y > 0.90:    # 90퍼센트 이상이면 인식\n",
    "            count += 1\n",
    "            \n",
    "    if count > 0:\n",
    "        print(str(i) + \"번째 신호등: \" + light_detect_img[i][0] + \" : \" + light_order[np.argmax(x)])\n",
    "        detect_img.append([light_detect_img[i][0], light_order[np.argmax(x)]])\n",
    "    else:\n",
    "        print(str(i)+\"번째 신호등: \" + light_detect_img[i][0] + \" : \" + light_order[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "27972419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['frame0_1.jpg', 'green'],\n",
       " ['frame0_2.jpg', 'green'],\n",
       " ['frame10_13.jpg', 'green'],\n",
       " ['frame10_14.jpg', 'green'],\n",
       " ['frame11_15.jpg', 'green'],\n",
       " ['frame11_16.jpg', 'green'],\n",
       " ['frame1_10.jpg', 'green'],\n",
       " ['frame1_9.jpg', 'green'],\n",
       " ['frame21_26.jpg', 'red'],\n",
       " ['frame22_32.jpg', 'red'],\n",
       " ['frame23_34.jpg', 'red'],\n",
       " ['frame24_38.jpg', 'red'],\n",
       " ['frame25_40.jpg', 'red'],\n",
       " ['frame25_43.jpg', 'red'],\n",
       " ['frame26_49.jpg', 'red'],\n",
       " ['frame26_51.jpg', 'red'],\n",
       " ['frame27_56.jpg', 'red'],\n",
       " ['frame27_58.jpg', 'red'],\n",
       " ['frame28_63.jpg', 'red'],\n",
       " ['frame28_66.jpg', 'red'],\n",
       " ['frame29_73.jpg', 'red'],\n",
       " ['frame29_75.jpg', 'red'],\n",
       " ['frame30_79.jpg', 'red'],\n",
       " ['frame30_83.jpg', 'red'],\n",
       " ['frame31_86.jpg', 'red'],\n",
       " ['frame31_90.jpg', 'red'],\n",
       " ['frame32_93.jpg', 'red'],\n",
       " ['frame32_95.jpg', 'red'],\n",
       " ['frame33_101.jpg', 'red'],\n",
       " ['frame33_99.jpg', 'red'],\n",
       " ['frame34_104.jpg', 'red'],\n",
       " ['frame34_106.jpg', 'red'],\n",
       " ['frame35_109.jpg', 'red'],\n",
       " ['frame35_112.jpg', 'red'],\n",
       " ['frame36_119.jpg', 'red'],\n",
       " ['frame36_122.jpg', 'red'],\n",
       " ['frame37_126.jpg', 'red'],\n",
       " ['frame37_128.jpg', 'red'],\n",
       " ['frame38_131.jpg', 'red'],\n",
       " ['frame38_133.jpg', 'red'],\n",
       " ['frame39_135.jpg', 'red'],\n",
       " ['frame39_136.jpg', 'red'],\n",
       " ['frame40_142.jpg', 'red'],\n",
       " ['frame40_144.jpg', 'red'],\n",
       " ['frame41_147.jpg', 'red'],\n",
       " ['frame41_150.jpg', 'red'],\n",
       " ['frame42_154.jpg', 'red'],\n",
       " ['frame42_156.jpg', 'red'],\n",
       " ['frame43_161.jpg', 'red'],\n",
       " ['frame43_163.jpg', 'red'],\n",
       " ['frame44_168.jpg', 'red'],\n",
       " ['frame44_170.jpg', 'red'],\n",
       " ['frame45_174.jpg', 'red'],\n",
       " ['frame45_176.jpg', 'red'],\n",
       " ['frame46_182.jpg', 'red'],\n",
       " ['frame46_184.jpg', 'red'],\n",
       " ['frame47_193.jpg', 'red'],\n",
       " ['frame48_203.jpg', 'red'],\n",
       " ['frame9_212.jpg', 'green'],\n",
       " ['frame9_213.jpg', 'green']]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "753bf2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 60\n"
     ]
    }
   ],
   "source": [
    "print(len(file_list_d),len(detect_img)) # 모델에 적용한 이미지, 이미지 검출 코드에서 나온거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f44a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = []\n",
    "for i in range(0, len(detect_img)):\n",
    "    for j in range(0, len(first_detect)):\n",
    "\n",
    "        if first_detect[j][1] == detect_img[i][0].split(\".\")[0]:\n",
    "            xy.append([first_detect[j][1], first_detect[j][0], detect_img[i][1]])\n",
    "    #print(detect_img[i][0].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fcadc51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['frame0_1', [542, 562, 795, 849], 'green'],\n",
       " ['frame0_2', [530, 550, 1011, 1074], 'green'],\n",
       " ['frame10_13', [481, 507, 737, 809], 'green'],\n",
       " ['frame10_14', [472, 497, 951, 1023], 'green'],\n",
       " ['frame11_15', [44, 100, 453, 603], 'green'],\n",
       " ['frame11_16', [22, 76, 961, 1111], 'green'],\n",
       " ['frame1_10', [297, 335, 1017, 1119], 'green'],\n",
       " ['frame1_9', [324, 354, 607, 694], 'green'],\n",
       " ['frame21_26', [611, 637, 931, 997], 'red'],\n",
       " ['frame22_32', [582, 612, 911, 983], 'red'],\n",
       " ['frame23_34', [549, 582, 892, 975], 'red'],\n",
       " ['frame24_38', [493, 529, 865, 953], 'red'],\n",
       " ['frame25_40', [628, 642, 942, 1000], 'red'],\n",
       " ['frame25_43', [427, 463, 841, 935], 'red'],\n",
       " ['frame26_49', [613, 639, 933, 1005], 'red'],\n",
       " ['frame26_51', [350, 394, 809, 919], 'red'],\n",
       " ['frame27_56', [600, 630, 929, 1001], 'red'],\n",
       " ['frame27_58', [271, 319, 775, 907], 'red'],\n",
       " ['frame28_63', [595, 621, 929, 995], 'red'],\n",
       " ['frame28_66', [211, 261, 757, 889], 'red'],\n",
       " ['frame29_73', [593, 619, 931, 997], 'red'],\n",
       " ['frame29_75', [167, 227, 741, 887], 'red'],\n",
       " ['frame30_79', [593, 619, 931, 997], 'red'],\n",
       " ['frame30_83', [158, 219, 738, 887], 'red'],\n",
       " ['frame31_86', [594, 619, 936, 997], 'red'],\n",
       " ['frame31_90', [159, 219, 743, 889], 'red'],\n",
       " ['frame32_93', [595, 621, 937, 1003], 'red'],\n",
       " ['frame32_95', [161, 221, 744, 890], 'red'],\n",
       " ['frame33_101', [161, 222, 743, 892], 'red'],\n",
       " ['frame33_99', [596, 621, 938, 999], 'red'],\n",
       " ['frame34_104', [594, 619, 940, 1001], 'red'],\n",
       " ['frame34_106', [159, 219, 746, 892], 'red'],\n",
       " ['frame35_109', [590, 615, 944, 1005], 'red'],\n",
       " ['frame35_112', [155, 215, 747, 901], 'red'],\n",
       " ['frame36_119', [587, 611, 946, 1004], 'red'],\n",
       " ['frame36_122', [151, 211, 749, 903], 'red'],\n",
       " ['frame37_126', [584, 609, 948, 1009], 'red'],\n",
       " ['frame37_128', [151, 208, 754, 900], 'red'],\n",
       " ['frame38_131', [584, 609, 948, 1009], 'red'],\n",
       " ['frame38_133', [149, 209, 754, 900], 'red'],\n",
       " ['frame39_135', [585, 609, 948, 1006], 'red'],\n",
       " ['frame39_136', [150, 211, 754, 903], 'red'],\n",
       " ['frame40_142', [585, 609, 948, 1006], 'red'],\n",
       " ['frame40_144', [149, 210, 754, 903], 'red'],\n",
       " ['frame41_147', [587, 608, 948, 1006], 'red'],\n",
       " ['frame41_150', [149, 209, 754, 900], 'red'],\n",
       " ['frame42_154', [587, 608, 948, 1003], 'red'],\n",
       " ['frame42_156', [154, 210, 757, 895], 'red'],\n",
       " ['frame43_161', [587, 608, 948, 1003], 'red'],\n",
       " ['frame43_163', [154, 208, 757, 895], 'red'],\n",
       " ['frame44_168', [587, 608, 950, 1005], 'red'],\n",
       " ['frame44_170', [156, 210, 758, 893], 'red'],\n",
       " ['frame45_174', [587, 608, 950, 1005], 'red'],\n",
       " ['frame45_176', [156, 210, 758, 890], 'red'],\n",
       " ['frame46_182', [592, 605, 954, 990], 'red'],\n",
       " ['frame46_184', [155, 205, 757, 889], 'red'],\n",
       " ['frame47_193', [157, 207, 760, 884], 'red'],\n",
       " ['frame48_203', [156, 207, 760, 887], 'red'],\n",
       " ['frame9_212', [598, 616, 810, 858], 'green'],\n",
       " ['frame9_213', [592, 610, 947, 995], 'green']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df51c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in range(0, len(xy)):\n",
    "    coor = xy[i][1]\n",
    "    color = xy[i][2]\n",
    "    for j in range(i+1, len(xy)):\n",
    "        if xy[i][0] == xy[j][0]:\n",
    "            coor = xy[j][1]\n",
    "            color = xy[j][2]\n",
    "    if [xy[i][0], coor, color] not in array:\n",
    "        array.append([xy[i][0], coor, color])\n",
    "    #print(xy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "42886183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['frame0_1', [542, 562, 795, 849], 'green'],\n",
       " ['frame0_2', [530, 550, 1011, 1074], 'green'],\n",
       " ['frame10_13', [481, 507, 737, 809], 'green'],\n",
       " ['frame10_14', [472, 497, 951, 1023], 'green'],\n",
       " ['frame11_15', [44, 100, 453, 603], 'green'],\n",
       " ['frame11_16', [22, 76, 961, 1111], 'green'],\n",
       " ['frame1_10', [297, 335, 1017, 1119], 'green'],\n",
       " ['frame1_9', [324, 354, 607, 694], 'green'],\n",
       " ['frame21_26', [611, 637, 931, 997], 'red'],\n",
       " ['frame22_32', [582, 612, 911, 983], 'red'],\n",
       " ['frame23_34', [549, 582, 892, 975], 'red'],\n",
       " ['frame24_38', [493, 529, 865, 953], 'red'],\n",
       " ['frame25_40', [628, 642, 942, 1000], 'red'],\n",
       " ['frame25_43', [427, 463, 841, 935], 'red'],\n",
       " ['frame26_49', [613, 639, 933, 1005], 'red'],\n",
       " ['frame26_51', [350, 394, 809, 919], 'red'],\n",
       " ['frame27_56', [600, 630, 929, 1001], 'red'],\n",
       " ['frame27_58', [271, 319, 775, 907], 'red'],\n",
       " ['frame28_63', [595, 621, 929, 995], 'red'],\n",
       " ['frame28_66', [211, 261, 757, 889], 'red'],\n",
       " ['frame29_73', [593, 619, 931, 997], 'red'],\n",
       " ['frame29_75', [167, 227, 741, 887], 'red'],\n",
       " ['frame30_79', [593, 619, 931, 997], 'red'],\n",
       " ['frame30_83', [158, 219, 738, 887], 'red'],\n",
       " ['frame31_86', [594, 619, 936, 997], 'red'],\n",
       " ['frame31_90', [159, 219, 743, 889], 'red'],\n",
       " ['frame32_93', [595, 621, 937, 1003], 'red'],\n",
       " ['frame32_95', [161, 221, 744, 890], 'red'],\n",
       " ['frame33_101', [161, 222, 743, 892], 'red'],\n",
       " ['frame33_99', [596, 621, 938, 999], 'red'],\n",
       " ['frame34_104', [594, 619, 940, 1001], 'red'],\n",
       " ['frame34_106', [159, 219, 746, 892], 'red'],\n",
       " ['frame35_109', [590, 615, 944, 1005], 'red'],\n",
       " ['frame35_112', [155, 215, 747, 901], 'red'],\n",
       " ['frame36_119', [587, 611, 946, 1004], 'red'],\n",
       " ['frame36_122', [151, 211, 749, 903], 'red'],\n",
       " ['frame37_126', [584, 609, 948, 1009], 'red'],\n",
       " ['frame37_128', [151, 208, 754, 900], 'red'],\n",
       " ['frame38_131', [584, 609, 948, 1009], 'red'],\n",
       " ['frame38_133', [149, 209, 754, 900], 'red'],\n",
       " ['frame39_135', [585, 609, 948, 1006], 'red'],\n",
       " ['frame39_136', [150, 211, 754, 903], 'red'],\n",
       " ['frame40_142', [585, 609, 948, 1006], 'red'],\n",
       " ['frame40_144', [149, 210, 754, 903], 'red'],\n",
       " ['frame41_147', [587, 608, 948, 1006], 'red'],\n",
       " ['frame41_150', [149, 209, 754, 900], 'red'],\n",
       " ['frame42_154', [587, 608, 948, 1003], 'red'],\n",
       " ['frame42_156', [154, 210, 757, 895], 'red'],\n",
       " ['frame43_161', [587, 608, 948, 1003], 'red'],\n",
       " ['frame43_163', [154, 208, 757, 895], 'red'],\n",
       " ['frame44_168', [587, 608, 950, 1005], 'red'],\n",
       " ['frame44_170', [156, 210, 758, 893], 'red'],\n",
       " ['frame45_174', [587, 608, 950, 1005], 'red'],\n",
       " ['frame45_176', [156, 210, 758, 890], 'red'],\n",
       " ['frame46_182', [592, 605, 954, 990], 'red'],\n",
       " ['frame46_184', [155, 205, 757, 889], 'red'],\n",
       " ['frame47_193', [157, 207, 760, 884], 'red'],\n",
       " ['frame48_203', [156, 207, 760, 887], 'red'],\n",
       " ['frame9_212', [598, 616, 810, 858], 'green'],\n",
       " ['frame9_213', [592, 610, 947, 995], 'green']]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221c398",
   "metadata": {},
   "source": [
    "# array에 담긴 파일명으로 원천 이미지에 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a1081",
   "metadata": {},
   "source": [
    "- path 경로에서 원천 이미지 찾아서 그 이미지에다가 rectangle 그리는 거여서 덮어씌워짐  \n",
    "- 덮어씌워지니까 원천 이미지는 꼭 백업해둘것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1464cde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame0_1 [542, 562, 795, 849] green\n",
      "./new_image/ frame0.png\n",
      "frame0_2 [530, 550, 1011, 1074] green\n",
      "./new_image/ frame0.png\n",
      "frame10_13 [481, 507, 737, 809] green\n",
      "./new_image/ frame10.png\n",
      "frame10_14 [472, 497, 951, 1023] green\n",
      "./new_image/ frame10.png\n",
      "frame11_15 [44, 100, 453, 603] green\n",
      "./new_image/ frame11.png\n",
      "frame11_16 [22, 76, 961, 1111] green\n",
      "./new_image/ frame11.png\n",
      "frame1_10 [297, 335, 1017, 1119] green\n",
      "./new_image/ frame1.png\n",
      "frame1_9 [324, 354, 607, 694] green\n",
      "./new_image/ frame1.png\n",
      "frame21_26 [611, 637, 931, 997] red\n",
      "./new_image/ frame21.png\n",
      "frame22_32 [582, 612, 911, 983] red\n",
      "./new_image/ frame22.png\n",
      "frame23_34 [549, 582, 892, 975] red\n",
      "./new_image/ frame23.png\n",
      "frame24_38 [493, 529, 865, 953] red\n",
      "./new_image/ frame24.png\n",
      "frame25_40 [628, 642, 942, 1000] red\n",
      "./new_image/ frame25.png\n",
      "frame25_43 [427, 463, 841, 935] red\n",
      "./new_image/ frame25.png\n",
      "frame26_49 [613, 639, 933, 1005] red\n",
      "./new_image/ frame26.png\n",
      "frame26_51 [350, 394, 809, 919] red\n",
      "./new_image/ frame26.png\n",
      "frame27_56 [600, 630, 929, 1001] red\n",
      "./new_image/ frame27.png\n",
      "frame27_58 [271, 319, 775, 907] red\n",
      "./new_image/ frame27.png\n",
      "frame28_63 [595, 621, 929, 995] red\n",
      "./new_image/ frame28.png\n",
      "frame28_66 [211, 261, 757, 889] red\n",
      "./new_image/ frame28.png\n",
      "frame29_73 [593, 619, 931, 997] red\n",
      "./new_image/ frame29.png\n",
      "frame29_75 [167, 227, 741, 887] red\n",
      "./new_image/ frame29.png\n",
      "frame30_79 [593, 619, 931, 997] red\n",
      "./new_image/ frame30.png\n",
      "frame30_83 [158, 219, 738, 887] red\n",
      "./new_image/ frame30.png\n",
      "frame31_86 [594, 619, 936, 997] red\n",
      "./new_image/ frame31.png\n",
      "frame31_90 [159, 219, 743, 889] red\n",
      "./new_image/ frame31.png\n",
      "frame32_93 [595, 621, 937, 1003] red\n",
      "./new_image/ frame32.png\n",
      "frame32_95 [161, 221, 744, 890] red\n",
      "./new_image/ frame32.png\n",
      "frame33_101 [161, 222, 743, 892] red\n",
      "./new_image/ frame33.png\n",
      "frame33_99 [596, 621, 938, 999] red\n",
      "./new_image/ frame33.png\n",
      "frame34_104 [594, 619, 940, 1001] red\n",
      "./new_image/ frame34.png\n",
      "frame34_106 [159, 219, 746, 892] red\n",
      "./new_image/ frame34.png\n",
      "frame35_109 [590, 615, 944, 1005] red\n",
      "./new_image/ frame35.png\n",
      "frame35_112 [155, 215, 747, 901] red\n",
      "./new_image/ frame35.png\n",
      "frame36_119 [587, 611, 946, 1004] red\n",
      "./new_image/ frame36.png\n",
      "frame36_122 [151, 211, 749, 903] red\n",
      "./new_image/ frame36.png\n",
      "frame37_126 [584, 609, 948, 1009] red\n",
      "./new_image/ frame37.png\n",
      "frame37_128 [151, 208, 754, 900] red\n",
      "./new_image/ frame37.png\n",
      "frame38_131 [584, 609, 948, 1009] red\n",
      "./new_image/ frame38.png\n",
      "frame38_133 [149, 209, 754, 900] red\n",
      "./new_image/ frame38.png\n",
      "frame39_135 [585, 609, 948, 1006] red\n",
      "./new_image/ frame39.png\n",
      "frame39_136 [150, 211, 754, 903] red\n",
      "./new_image/ frame39.png\n",
      "frame40_142 [585, 609, 948, 1006] red\n",
      "./new_image/ frame40.png\n",
      "frame40_144 [149, 210, 754, 903] red\n",
      "./new_image/ frame40.png\n",
      "frame41_147 [587, 608, 948, 1006] red\n",
      "./new_image/ frame41.png\n",
      "frame41_150 [149, 209, 754, 900] red\n",
      "./new_image/ frame41.png\n",
      "frame42_154 [587, 608, 948, 1003] red\n",
      "./new_image/ frame42.png\n",
      "frame42_156 [154, 210, 757, 895] red\n",
      "./new_image/ frame42.png\n",
      "frame43_161 [587, 608, 948, 1003] red\n",
      "./new_image/ frame43.png\n",
      "frame43_163 [154, 208, 757, 895] red\n",
      "./new_image/ frame43.png\n",
      "frame44_168 [587, 608, 950, 1005] red\n",
      "./new_image/ frame44.png\n",
      "frame44_170 [156, 210, 758, 893] red\n",
      "./new_image/ frame44.png\n",
      "frame45_174 [587, 608, 950, 1005] red\n",
      "./new_image/ frame45.png\n",
      "frame45_176 [156, 210, 758, 890] red\n",
      "./new_image/ frame45.png\n",
      "frame46_182 [592, 605, 954, 990] red\n",
      "./new_image/ frame46.png\n",
      "frame46_184 [155, 205, 757, 889] red\n",
      "./new_image/ frame46.png\n",
      "frame47_193 [157, 207, 760, 884] red\n",
      "./new_image/ frame47.png\n",
      "frame48_203 [156, 207, 760, 887] red\n",
      "./new_image/ frame48.png\n",
      "frame9_212 [598, 616, 810, 858] green\n",
      "./new_image/ frame9.png\n",
      "frame9_213 [592, 610, 947, 995] green\n",
      "./new_image/ frame9.png\n"
     ]
    }
   ],
   "source": [
    "path = './new_image/'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "for a,b,c in array:\n",
    "    print(a,b,c)\n",
    "    imgname = a.split('_')[0] + '.png'\n",
    "    print(path,imgname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8749ea0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame0_1 [542, 562, 795, 849] green\n",
      "frame0_2 [530, 550, 1011, 1074] green\n",
      "frame10_13 [481, 507, 737, 809] green\n",
      "frame10_14 [472, 497, 951, 1023] green\n",
      "frame11_15 [44, 100, 453, 603] green\n",
      "frame11_16 [22, 76, 961, 1111] green\n",
      "frame1_10 [297, 335, 1017, 1119] green\n",
      "frame1_9 [324, 354, 607, 694] green\n",
      "frame21_26 [611, 637, 931, 997] red\n",
      "frame22_32 [582, 612, 911, 983] red\n",
      "frame23_34 [549, 582, 892, 975] red\n",
      "frame24_38 [493, 529, 865, 953] red\n",
      "frame25_40 [628, 642, 942, 1000] red\n",
      "frame25_43 [427, 463, 841, 935] red\n",
      "frame26_49 [613, 639, 933, 1005] red\n",
      "frame26_51 [350, 394, 809, 919] red\n",
      "frame27_56 [600, 630, 929, 1001] red\n",
      "frame27_58 [271, 319, 775, 907] red\n",
      "frame28_63 [595, 621, 929, 995] red\n",
      "frame28_66 [211, 261, 757, 889] red\n",
      "frame29_73 [593, 619, 931, 997] red\n",
      "frame29_75 [167, 227, 741, 887] red\n",
      "frame30_79 [593, 619, 931, 997] red\n",
      "frame30_83 [158, 219, 738, 887] red\n",
      "frame31_86 [594, 619, 936, 997] red\n",
      "frame31_90 [159, 219, 743, 889] red\n",
      "frame32_93 [595, 621, 937, 1003] red\n",
      "frame32_95 [161, 221, 744, 890] red\n",
      "frame33_101 [161, 222, 743, 892] red\n",
      "frame33_99 [596, 621, 938, 999] red\n",
      "frame34_104 [594, 619, 940, 1001] red\n",
      "frame34_106 [159, 219, 746, 892] red\n",
      "frame35_109 [590, 615, 944, 1005] red\n",
      "frame35_112 [155, 215, 747, 901] red\n",
      "frame36_119 [587, 611, 946, 1004] red\n",
      "frame36_122 [151, 211, 749, 903] red\n",
      "frame37_126 [584, 609, 948, 1009] red\n",
      "frame37_128 [151, 208, 754, 900] red\n",
      "frame38_131 [584, 609, 948, 1009] red\n",
      "frame38_133 [149, 209, 754, 900] red\n",
      "frame39_135 [585, 609, 948, 1006] red\n",
      "frame39_136 [150, 211, 754, 903] red\n",
      "frame40_142 [585, 609, 948, 1006] red\n",
      "frame40_144 [149, 210, 754, 903] red\n",
      "frame41_147 [587, 608, 948, 1006] red\n",
      "frame41_150 [149, 209, 754, 900] red\n",
      "frame42_154 [587, 608, 948, 1003] red\n",
      "frame42_156 [154, 210, 757, 895] red\n",
      "frame43_161 [587, 608, 948, 1003] red\n",
      "frame43_163 [154, 208, 757, 895] red\n",
      "frame44_168 [587, 608, 950, 1005] red\n",
      "frame44_170 [156, 210, 758, 893] red\n",
      "frame45_174 [587, 608, 950, 1005] red\n",
      "frame45_176 [156, 210, 758, 890] red\n",
      "frame46_182 [592, 605, 954, 990] red\n",
      "frame46_184 [155, 205, 757, 889] red\n",
      "frame47_193 [157, 207, 760, 884] red\n",
      "frame48_203 [156, 207, 760, 887] red\n",
      "frame9_212 [598, 616, 810, 858] green\n",
      "frame9_213 [592, 610, 947, 995] green\n"
     ]
    }
   ],
   "source": [
    "# 원천이미지 있는 디렉토리 경로\n",
    "# 해당 디렉토리 백업해두기\n",
    "path = './new_image/'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "for a,b,c in array:\n",
    "    print(a,b,c)\n",
    "    imgname = a.split('_')[0]+'.png'\n",
    "    img = cv2.imread(path+imgname)\n",
    "    y,h,x,w = b\n",
    "    w = w - x\n",
    "    h = h - y\n",
    "    text = c \n",
    "    org = (x, y - 8)\n",
    "    \n",
    "    if x > 0 and y > 0 and w > 0 and h > 0:\n",
    "        cv2.rectangle(img, (x, y, w, h), (139, 255, 224), 2)\n",
    "        cv2.putText(img, text, org, font, 0.7, (139, 255, 224), 2)\n",
    "        \n",
    "    # 기존 원천 이미지에 덮어쓰기 되는거니까 주의!!!\n",
    "    cv2.imwrite(path + imgname, img)\n",
    "\n",
    "\n",
    "    #print(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425b126",
   "metadata": {},
   "source": [
    "# 원천 이미지 연속 출력 (검출된 내용 반영)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d0261",
   "metadata": {},
   "source": [
    "#### 숫자 정렬용 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e46adaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ce2db8ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import natsort # 숫자 정렬용 라이브러리\n",
    "\n",
    "# images에 있는 모든 jpg 파일을 img_files 리스트에 추가\n",
    "img_files = glob.glob('.\\\\new_image\\\\*.png')\n",
    "# img_files.sort()\n",
    "\n",
    "# 문자열로 인식해서 [1, 10, ..., 2] 이런식으로 나오는 오류\n",
    "# natsort 사용하여 [1, 2, ..., 10] 순으로 나올 수 있도록 정렬\n",
    "img_files = natsort.natsorted(img_files)\n",
    "\n",
    "# 이미지 없을때 예외처리\n",
    "if not img_files:\n",
    "    print(\"jpg 이미지가 없다..\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# 슬라이드 쇼 반복을 위한 반복문\n",
    "count = len(img_files)\n",
    "index = 0\n",
    "\n",
    "while index < count:\n",
    "    img = cv2.imread(img_files[index])\n",
    "    name = img_files[index].split('\\\\')[2]\n",
    "    filepath = img_files[index]\n",
    "\t# 예외처리\n",
    "    if img is None:     \n",
    "        print(\"이미지를 불러오는데 실패했습니다.\")\n",
    "        break\n",
    "        \n",
    "\t# ESC가 입력되면 break\n",
    "    cv2.imshow('video_test', img)\n",
    "    if cv2.waitKey(1000) == 27:     \n",
    "        break\n",
    "\n",
    "\t# index가 이미지 리스트보다 커지거나 같아지면 다시 0으로\n",
    "    index += 1      \n",
    "    \n",
    "    #if index >= count :\n",
    "        #index = 0 \n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6509a",
   "metadata": {},
   "source": [
    "# 동영상으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d71a2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    " \n",
    "img_array = []\n",
    "\n",
    "filename_list = glob.glob('.\\\\new_image\\\\*.png')\n",
    "filename_list = natsort.natsorted(filename_list)\n",
    "\n",
    "for filename in filename_list:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width, height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('video_test.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 3, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe25d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
